![alt text](image.png)

estimated time: 2 hrs

# Knowledge Distillation

- read the paper [A Survey on Knowledge Distillation of Large Language Models](https://arxiv.org/abs/2402.13116)


## Notes

![alt text](1.jpg)